{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EDA_Feature_based_classifier",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTtj3J7x2FpJ",
        "colab_type": "text"
      },
      "source": [
        "**Data Visualization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2703jFG2d9s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Word Cloud\n",
        "from wordcloud import WordCloud\n",
        "train_q = pd.Series(df['question1'].tolist() + df['question2'].tolist()).astype(str)\n",
        "cloud = WordCloud(width=1440, height=1080).generate(\" \".join(train_q.astype(str)))\n",
        "plt.figure(figsize=(20, 15))\n",
        "plt.imshow(cloud)\n",
        "plt.axis('off')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yxKI9JL-C_X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Loading the pickle file with the extracted features\n",
        "df4= pd.read_pickle('/content/drive/My Drive/Final_DF_question_pair.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqXoJJzs9R6o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Comparing common words between the question pairs and word share as features\n",
        "plt.subplot(1,2,1)\n",
        "sns.distplot(df4[df4['is_duplicate'] == 1.0]['word_Common'][0:] , label = \"1\", color = 'red')\n",
        "sns.distplot(df4[df4['is_duplicate'] == 0.0]['word_Common'][0:] , label = \"0\" , color = 'blue' )\n",
        "\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "sns.distplot(df4[df4['is_duplicate'] == 1.0]['word_share'][0:] , label = \"1\", color = 'red')\n",
        "sns.distplot(df4[df4['is_duplicate'] == 0.0]['word_share'][0:] , label = \"0\" , color = 'blue' )\n",
        "y.label()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Umkk6xsA2Dxy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#PairPlot\n",
        "import seaborn as sns\n",
        "n = 10000\n",
        "sns.pairplot(df4[['len_q1','len_q2', 'diff_len', 'len_char_q1', 'len_char_q2',\n",
        "                  'len_word_q1','len_word_q2', 'common_words','is_duplicate']][0:n],hue= 'is_duplicate')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oGCujhS-v3q",
        "colab_type": "text"
      },
      "source": [
        "**Subset Model Implementation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIZ84OZk_CSM",
        "colab_type": "text"
      },
      "source": [
        "**Logistic Regression**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63d0LJ93_HfO",
        "colab_type": "text"
      },
      "source": [
        "Basic Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-wXA4xarzUk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X1 = df4.iloc[:,15:22]\n",
        "y1 = df4['is_duplicate']\n",
        "X1_train, X1_test, y1_train, y1_test =  train_test_split(X1, y1, test_size=0.2, random_state=42)\n",
        "X1_train, X1_val, y1_train, y1_val = train_test_split(X1_train, y1_train, test_size=0.13, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PpW86pcAVgE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#logistic regression with hyperparameter tuning:\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "logr_model = LogisticRegression(random_state=42)\n",
        "param_grid = {'C': np.logspace(-2, 7, 10),\n",
        "             'tol': np.logspace(-5, -1, 5)\n",
        "             }\n",
        "logr_cv = RandomizedSearchCV(logr_model, param_distributions=param_grid, cv=5, n_jobs=-1)\n",
        "logr_cv.fit(X1_train, y1_train)\n",
        "logr_model = LogisticRegression(random_state=42, \n",
        "                                C=logr_cv.best_params_['C'], \n",
        "                                tol=logr_cv.best_params_['tol'], \n",
        "                                n_jobs=-1)\n",
        "logr_model.fit(X1_train, y1_train)\n",
        "\n",
        "# predict using test set\n",
        "# X_test_features contains all features from feature sets 1,2 & 3 for the test set question-pairs\n",
        "logr_pred = logr_model.predict(X1_test)\n",
        "C = confusion_matrix(y1_test, logr_pred,labels = [1,0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwE17nZBAdw3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "average_precision = average_precision_score(y1_test, logr_pred)\n",
        "print('confusion_matrix',C)\n",
        "print('Average precision-recall score: {0:0.2f}'.format(\n",
        "      average_precision))\n",
        "score =accuracy_score(y1_test,logr_pred)\n",
        "print(\"Accuracy of Logistic Regression:\",score)\n",
        "\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "import matplotlib.pyplot as plt\n",
        "from inspect import signature\n",
        "\n",
        "precision, recall, _ = precision_recall_curve(y1_test, logr_pred)\n",
        "\n",
        "step_kwargs = ({'step': 'post'}\n",
        "               if 'step' in signature(plt.fill_between).parameters\n",
        "               else {})\n",
        "plt.step(recall, precision, color='b', alpha=0.2,\n",
        "         where='post')\n",
        "plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
        "\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(\n",
        "          average_precision))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mISL9v9sAmny"
      },
      "source": [
        "Word2Vec Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HWYunULfAmn2",
        "colab": {}
      },
      "source": [
        "X1 = df4.iloc[:,1:14]\n",
        "y1 = df4['is_duplicate']\n",
        "X1_train, X1_test, y1_train, y1_test =  train_test_split(X1, y1, test_size=0.2, random_state=42)\n",
        "X1_train, X1_val, y1_train, y1_val = train_test_split(X1_train, y1_train, test_size=0.13, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PrY6EOx3Amn6",
        "colab": {}
      },
      "source": [
        "#logistic regression with hyperparameter tuning:\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "logr_model = LogisticRegression(random_state=42)\n",
        "param_grid = {'C': np.logspace(-2, 7, 10),\n",
        "             'tol': np.logspace(-5, -1, 5)\n",
        "             }\n",
        "logr_cv = RandomizedSearchCV(logr_model, param_distributions=param_grid, cv=5, n_jobs=-1)\n",
        "logr_cv.fit(X1_train, y1_train)\n",
        "logr_model = LogisticRegression(random_state=42, \n",
        "                                C=logr_cv.best_params_['C'], \n",
        "                                tol=logr_cv.best_params_['tol'], \n",
        "                                n_jobs=-1)\n",
        "logr_model.fit(X1_train, y1_train)\n",
        "\n",
        "# predict using test set\n",
        "# X_test_features contains all features from feature sets 1,2 & 3 for the test set question-pairs\n",
        "logr_pred = logr_model.predict(X1_test)\n",
        "C = confusion_matrix(y1_test, logr_pred,labels = [1,0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zpIX_oc7Amn9",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "average_precision = average_precision_score(y1_test, logr_pred)\n",
        "print('confusion_matrix',C)\n",
        "print('Average precision-recall score: {0:0.2f}'.format(\n",
        "      average_precision))\n",
        "score =accuracy_score(y1_test,logr_pred)\n",
        "print(\"Accuracy of Logistic Regression:\",score)\n",
        "\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "import matplotlib.pyplot as plt\n",
        "from inspect import signature\n",
        "\n",
        "precision, recall, _ = precision_recall_curve(y1_test, logr_pred)\n",
        "\n",
        "step_kwargs = ({'step': 'post'}\n",
        "               if 'step' in signature(plt.fill_between).parameters\n",
        "               else {})\n",
        "plt.step(recall, precision, color='b', alpha=0.2,\n",
        "         where='post')\n",
        "plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
        "\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(\n",
        "          average_precision))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_4slGZFfA7R1"
      },
      "source": [
        "Basic+Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Bjvf2IMcA7R3",
        "colab": {}
      },
      "source": [
        "X1 = df4.iloc[:,1:22]\n",
        "y1 = df4['is_duplicate']\n",
        "X1_train, X1_test, y1_train, y1_test =  train_test_split(X1, y1, test_size=0.2, random_state=42)\n",
        "X1_train, X1_val, y1_train, y1_val = train_test_split(X1_train, y1_train, test_size=0.13, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s9Zp-mtgA7R6",
        "colab": {}
      },
      "source": [
        "#logistic regression with hyperparameter tuning:\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "logr_model = LogisticRegression(random_state=42)\n",
        "param_grid = {'C': np.logspace(-2, 7, 10),\n",
        "             'tol': np.logspace(-5, -1, 5)\n",
        "             }\n",
        "logr_cv = RandomizedSearchCV(logr_model, param_distributions=param_grid, cv=5, n_jobs=-1)\n",
        "logr_cv.fit(X1_train, y1_train)\n",
        "logr_model = LogisticRegression(random_state=42, \n",
        "                                C=logr_cv.best_params_['C'], \n",
        "                                tol=logr_cv.best_params_['tol'], \n",
        "                                n_jobs=-1)\n",
        "logr_model.fit(X1_train, y1_train)\n",
        "\n",
        "# predict using test set\n",
        "# X_test_features contains all features from feature sets 1,2 & 3 for the test set question-pairs\n",
        "logr_pred = logr_model.predict(X1_test)\n",
        "C = confusion_matrix(y1_test, logr_pred,labels = [1,0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hEZ-1J11A7R_",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "average_precision = average_precision_score(y1_test, logr_pred)\n",
        "print('confusion_matrix',C)\n",
        "print('Average precision-recall score: {0:0.2f}'.format(\n",
        "      average_precision))\n",
        "score =accuracy_score(y1_test,logr_pred)\n",
        "print(\"Accuracy of Logistic Regression:\",score)\n",
        "\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "import matplotlib.pyplot as plt\n",
        "from inspect import signature\n",
        "\n",
        "precision, recall, _ = precision_recall_curve(y1_test, logr_pred)\n",
        "\n",
        "step_kwargs = ({'step': 'post'}\n",
        "               if 'step' in signature(plt.fill_between).parameters\n",
        "               else {})\n",
        "plt.step(recall, precision, color='b', alpha=0.2,\n",
        "         where='post')\n",
        "plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
        "\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(\n",
        "          average_precision))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8QiwgSS_A9CD"
      },
      "source": [
        "Fuzzy Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yoEsfjeDA9CE",
        "colab": {}
      },
      "source": [
        "X1 = df4.iloc[:,23:31]\n",
        "y1 = df4['is_duplicate']\n",
        "X1_train, X1_test, y1_train, y1_test =  train_test_split(X1, y1, test_size=0.2, random_state=42)\n",
        "X1_train, X1_val, y1_train, y1_val = train_test_split(X1_train, y1_train, test_size=0.13, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jiQEY2FvA9CI",
        "colab": {}
      },
      "source": [
        "#logistic regression with hyperparameter tuning:\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "logr_model = LogisticRegression(random_state=42)\n",
        "param_grid = {'C': np.logspace(-2, 7, 10),\n",
        "             'tol': np.logspace(-5, -1, 5)\n",
        "             }\n",
        "logr_cv = RandomizedSearchCV(logr_model, param_distributions=param_grid, cv=5, n_jobs=-1)\n",
        "logr_cv.fit(X1_train, y1_train)\n",
        "logr_model = LogisticRegression(random_state=42, \n",
        "                                C=logr_cv.best_params_['C'], \n",
        "                                tol=logr_cv.best_params_['tol'], \n",
        "                                n_jobs=-1)\n",
        "logr_model.fit(X1_train, y1_train)\n",
        "\n",
        "# predict using test set\n",
        "# X_test_features contains all features from feature sets 1,2 & 3 for the test set question-pairs\n",
        "logr_pred = logr_model.predict(X1_test)\n",
        "C = confusion_matrix(y1_test, logr_pred,labels = [1,0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vdmlHaHkA9CL",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "average_precision = average_precision_score(y1_test, logr_pred)\n",
        "print('confusion_matrix',C)\n",
        "print('Average precision-recall score: {0:0.2f}'.format(\n",
        "      average_precision))\n",
        "score =accuracy_score(y1_test,logr_pred)\n",
        "print(\"Accuracy of Logistic Regression:\",score)\n",
        "\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "import matplotlib.pyplot as plt\n",
        "from inspect import signature\n",
        "\n",
        "precision, recall, _ = precision_recall_curve(y1_test, logr_pred)\n",
        "\n",
        "step_kwargs = ({'step': 'post'}\n",
        "               if 'step' in signature(plt.fill_between).parameters\n",
        "               else {})\n",
        "plt.step(recall, precision, color='b', alpha=0.2,\n",
        "         where='post')\n",
        "plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
        "\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(\n",
        "          average_precision))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QbU-u18_A_bd"
      },
      "source": [
        "Fuzzy+Basic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "scQTe-7oA_be",
        "colab": {}
      },
      "source": [
        "X1 = df4.iloc[:,15:31]\n",
        "y1 = df4['is_duplicate']\n",
        "X1_train, X1_test, y1_train, y1_test =  train_test_split(X1, y1, test_size=0.2, random_state=42)\n",
        "X1_train, X1_val, y1_train, y1_val = train_test_split(X1_train, y1_train, test_size=0.13, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9EeiUZPHA_bh",
        "colab": {}
      },
      "source": [
        "#logistic regression with hyperparameter tuning:\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "logr_model = LogisticRegression(random_state=42)\n",
        "param_grid = {'C': np.logspace(-2, 7, 10),\n",
        "             'tol': np.logspace(-5, -1, 5)\n",
        "             }\n",
        "logr_cv = RandomizedSearchCV(logr_model, param_distributions=param_grid, cv=5, n_jobs=-1)\n",
        "logr_cv.fit(X1_train, y1_train)\n",
        "logr_model = LogisticRegression(random_state=42, \n",
        "                                C=logr_cv.best_params_['C'], \n",
        "                                tol=logr_cv.best_params_['tol'], \n",
        "                                n_jobs=-1)\n",
        "logr_model.fit(X1_train, y1_train)\n",
        "\n",
        "# predict using test set\n",
        "# X_test_features contains all features from feature sets 1,2 & 3 for the test set question-pairs\n",
        "logr_pred = logr_model.predict(X1_test)\n",
        "C = confusion_matrix(y1_test, logr_pred,labels = [1,0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3dj8cdxwA_bk",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "average_precision = average_precision_score(y1_test, logr_pred)\n",
        "print('confusion_matrix',C)\n",
        "print('Average precision-recall score: {0:0.2f}'.format(\n",
        "      average_precision))\n",
        "score =accuracy_score(y1_test,logr_pred)\n",
        "print(\"Accuracy of Logistic Regression:\",score)\n",
        "\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "import matplotlib.pyplot as plt\n",
        "from inspect import signature\n",
        "\n",
        "precision, recall, _ = precision_recall_curve(y1_test, logr_pred)\n",
        "\n",
        "step_kwargs = ({'step': 'post'}\n",
        "               if 'step' in signature(plt.fill_between).parameters\n",
        "               else {})\n",
        "plt.step(recall, precision, color='b', alpha=0.2,\n",
        "         where='post')\n",
        "plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
        "\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(\n",
        "          average_precision))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SbKD6ft9BBja"
      },
      "source": [
        "Fuzzy + Word2Vev Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3r5ZkFRGBBjc",
        "colab": {}
      },
      "source": [
        "rng = list(range(1,15)) + list(range(23,30))\n",
        "X1 = df4.iloc[:,rng]\n",
        "y1 = df4['is_duplicate']\n",
        "X1_train, X1_test, y1_train, y1_test =  train_test_split(X1, y1, test_size=0.2, random_state=42)\n",
        "X1_train, X1_val, y1_train, y1_val = train_test_split(X1_train, y1_train, test_size=0.13, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HfQCtnXxBBjg",
        "colab": {}
      },
      "source": [
        "#logistic regression with hyperparameter tuning:\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "logr_model = LogisticRegression(random_state=42)\n",
        "param_grid = {'C': np.logspace(-2, 7, 10),\n",
        "             'tol': np.logspace(-5, -1, 5)\n",
        "             }\n",
        "logr_cv = RandomizedSearchCV(logr_model, param_distributions=param_grid, cv=5, n_jobs=-1)\n",
        "logr_cv.fit(X1_train, y1_train)\n",
        "logr_model = LogisticRegression(random_state=42, \n",
        "                                C=logr_cv.best_params_['C'], \n",
        "                                tol=logr_cv.best_params_['tol'], \n",
        "                                n_jobs=-1)\n",
        "logr_model.fit(X1_train, y1_train)\n",
        "\n",
        "# predict using test set\n",
        "# X_test_features contains all features from feature sets 1,2 & 3 for the test set question-pairs\n",
        "logr_pred = logr_model.predict(X1_test)\n",
        "C = confusion_matrix(y1_test, logr_pred,labels = [1,0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P5GDBAjXBBji",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "average_precision = average_precision_score(y1_test, logr_pred)\n",
        "print('confusion_matrix',C)\n",
        "print('Average precision-recall score: {0:0.2f}'.format(\n",
        "      average_precision))\n",
        "score =accuracy_score(y1_test,logr_pred)\n",
        "print(\"Accuracy of Logistic Regression:\",score)\n",
        "\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "import matplotlib.pyplot as plt\n",
        "from inspect import signature\n",
        "\n",
        "precision, recall, _ = precision_recall_curve(y1_test, logr_pred)\n",
        "\n",
        "step_kwargs = ({'step': 'post'}\n",
        "               if 'step' in signature(plt.fill_between).parameters\n",
        "               else {})\n",
        "plt.step(recall, precision, color='b', alpha=0.2,\n",
        "         where='post')\n",
        "plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
        "\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(\n",
        "          average_precision))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2xAfBJTD-nO",
        "colab_type": "text"
      },
      "source": [
        "**Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2PXGJSs3hZh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X1 = df4.iloc[:,15:22]\n",
        "y1 = df4['is_duplicate']\n",
        "X1_train, X1_test, y1_train, y1_test =  train_test_split(X1, y1, test_size=0.2, random_state=42)\n",
        "X1_train, X1_val, y1_train, y1_val = train_test_split(X1_train, y1_train, test_size=0.13, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hRqY5Y8c3lO9",
        "colab": {}
      },
      "source": [
        "#Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier as RFC\n",
        "estimators = [100,150,200,300,400,600,800]\n",
        "\n",
        "test_scores = []\n",
        "train_scores = []\n",
        "for i in estimators:\n",
        "    clf = RFC(n_estimators=i,n_jobs=-1)\n",
        "    clf.fit(X1_train,y1_train)\n",
        "    predict_y = clf.predict_proba(X1_train)\n",
        "    log_loss_train = log_loss(y1_train, predict_y, eps=1e-15)\n",
        "    train_scores.append(log_loss_train)\n",
        "    predict_y = clf.predict_proba(X1_test)\n",
        "    log_loss_test = log_loss(y1_test, predict_y, eps=1e-15)\n",
        "    test_scores.append(log_loss_test)\n",
        "    print('estimators = ',i,'Train Log Loss ',log_loss_train,'Test Log Loss ',log_loss_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bSgzthM93lPE",
        "colab": {}
      },
      "source": [
        "\n",
        "Depth = [5,10,12,15,20,25,50]\n",
        "test_scores = []\n",
        "train_scores = []\n",
        "for i in Depth:\n",
        "    clf = RFC(n_estimators=100,max_depth=i,n_jobs=-1)\n",
        "    clf.fit(X1_train,y1_train)\n",
        "    predict_y = clf.predict_proba(X1_train)\n",
        "    log_loss_train = log_loss(y1_train, predict_y, eps=1e-15)\n",
        "    train_scores.append(log_loss_train)\n",
        "    predict_y = clf.predict_proba(X1_test)\n",
        "    log_loss_test = log_loss(y1_test, predict_y, eps=1e-15)\n",
        "    test_scores.append(log_loss_test)\n",
        "    print('Depth = ',i,'Train Log Loss ',log_loss_train,'Test Log Loss ',log_loss_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IBXjCQ2T3lPH",
        "colab": {}
      },
      "source": [
        "#optimum depth = 11, optimum components = 400:\n",
        "clf = RFC(n_estimators=400,max_depth=11,n_jobs=-1)\n",
        "clf.fit(X1_train,y1_train)\n",
        "y_pred_rf = clf.predict(X1_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qWHdPtzK3lPL",
        "colab": {}
      },
      "source": [
        "confusion_matrix_rf = confusion_matrix(y1_test, y_pred_rf,labels = [1,0])\n",
        "print(confusion_matrix_rf)\n",
        "\n",
        "accuracy_rf = accuracy_score(y1_test,y_pred_rf)\n",
        "print(accuracy_rf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NGTg2gHS3lPN",
        "colab": {}
      },
      "source": [
        "# RANDOM FOREST METRICS:- plot the confusion matrix, Average precision Recall, F1 score-\n",
        "from sklearn.metrics import f1_score,precision_score,recall_score\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from inspect import signature\n",
        "\n",
        "\n",
        "average_precision = average_precision_score(y1_test,y_pred_rf)    \n",
        "f1_score_rf = f1_score(y1_test,y_pred_rf)\n",
        "print(\"F1 Score of Random Forest classifier is:\",f1_score_rf)\n",
        "print(\"Confusion Matrix for Random Forest is:\",confusion_matrix_rf)\n",
        "print(\"precision score:\",precision_score(y1_test, y_pred_rf))\n",
        "print(\"Recall:\",recall_score(y1_test,y_pred_rf))\n",
        "print(\"Accuracy:\",accuracy_rf)\n",
        "print(\"Average Precision Recall Score:\",average_precision)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyNuOwdC9TdT",
        "colab_type": "text"
      },
      "source": [
        "Word2Vec Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kL7RHgje9mhy",
        "colab": {}
      },
      "source": [
        "X1 = df4.iloc[:,1:14]\n",
        "y1 = df4['is_duplicate']\n",
        "X1_train, X1_test, y1_train, y1_test =  train_test_split(X1, y1, test_size=0.2, random_state=42)\n",
        "X1_train, X1_val, y1_train, y1_val = train_test_split(X1_train, y1_train, test_size=0.13, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Js0W3abR9mh4",
        "colab": {}
      },
      "source": [
        "#Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier as RFC\n",
        "estimators = [100,150,200,300,400,600,800]\n",
        "\n",
        "test_scores = []\n",
        "train_scores = []\n",
        "for i in estimators:\n",
        "    clf = RFC(n_estimators=i,n_jobs=-1)\n",
        "    clf.fit(X1_train,y1_train)\n",
        "    predict_y = clf.predict_proba(X1_train)\n",
        "    log_loss_train = log_loss(y1_train, predict_y, eps=1e-15)\n",
        "    train_scores.append(log_loss_train)\n",
        "    predict_y = clf.predict_proba(X1_test)\n",
        "    log_loss_test = log_loss(y1_test, predict_y, eps=1e-15)\n",
        "    test_scores.append(log_loss_test)\n",
        "    print('estimators = ',i,'Train Log Loss ',log_loss_train,'Test Log Loss ',log_loss_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cjLVb57n9mh8",
        "colab": {}
      },
      "source": [
        "\n",
        "Depth = [5,10,12,15,20,25,50]\n",
        "test_scores = []\n",
        "train_scores = []\n",
        "for i in Depth:\n",
        "    clf = RFC(n_estimators=100,max_depth=i,n_jobs=-1)\n",
        "    clf.fit(X1_train,y1_train)\n",
        "    predict_y = clf.predict_proba(X1_train)\n",
        "    log_loss_train = log_loss(y1_train, predict_y, eps=1e-15)\n",
        "    train_scores.append(log_loss_train)\n",
        "    predict_y = clf.predict_proba(X1_test)\n",
        "    log_loss_test = log_loss(y1_test, predict_y, eps=1e-15)\n",
        "    test_scores.append(log_loss_test)\n",
        "    print('Depth = ',i,'Train Log Loss ',log_loss_train,'Test Log Loss ',log_loss_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BBaGS8BI9mh-",
        "colab": {}
      },
      "source": [
        "#optimum depth = 11, optimum components = 400:\n",
        "clf = RFC(n_estimators=400,max_depth=11,n_jobs=-1)\n",
        "clf.fit(X1_train,y1_train)\n",
        "y_pred_rf = clf.predict(X1_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BHeYZ5VD9miB",
        "colab": {}
      },
      "source": [
        "confusion_matrix_rf = confusion_matrix(y1_test, y_pred_rf,labels = [1,0])\n",
        "print(confusion_matrix_rf)\n",
        "\n",
        "accuracy_rf = accuracy_score(y1_test,y_pred_rf)\n",
        "print(accuracy_rf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s1p_teOQ9miD",
        "colab": {}
      },
      "source": [
        "# RANDOM FOREST METRICS:- plot the confusion matrix, Average precision Recall, F1 score-\n",
        "from sklearn.metrics import f1_score,precision_score,recall_score\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from inspect import signature\n",
        "\n",
        "\n",
        "average_precision = average_precision_score(y1_test,y_pred_rf)    \n",
        "f1_score_rf = f1_score(y1_test,y_pred_rf)\n",
        "print(\"F1 Score of Random Forest classifier is:\",f1_score_rf)\n",
        "print(\"Confusion Matrix for Random Forest is:\",confusion_matrix_rf)\n",
        "print(\"precision score:\",precision_score(y1_test, y_pred_rf))\n",
        "print(\"Recall:\",recall_score(y1_test,y_pred_rf))\n",
        "print(\"Accuracy:\",accuracy_rf)\n",
        "print(\"Average Precision Recall Score:\",average_precision)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SoZGPnoFoB9",
        "colab_type": "text"
      },
      "source": [
        "Basic + Word2Vec Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RecjHDX_Ft_U",
        "colab": {}
      },
      "source": [
        "X1 = df4.iloc[:,1:22]\n",
        "y1 = df4['is_duplicate']\n",
        "X1_train, X1_test, y1_train, y1_test =  train_test_split(X1, y1, test_size=0.2, random_state=42)\n",
        "X1_train, X1_val, y1_train, y1_val = train_test_split(X1_train, y1_train, test_size=0.13, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QujrjcBjFt_X",
        "colab": {}
      },
      "source": [
        "#Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier as RFC\n",
        "estimators = [100,150,200,300,400,600,800]\n",
        "\n",
        "test_scores = []\n",
        "train_scores = []\n",
        "for i in estimators:\n",
        "    clf = RFC(n_estimators=i,n_jobs=-1)\n",
        "    clf.fit(X1_train,y1_train)\n",
        "    predict_y = clf.predict_proba(X1_train)\n",
        "    log_loss_train = log_loss(y1_train, predict_y, eps=1e-15)\n",
        "    train_scores.append(log_loss_train)\n",
        "    predict_y = clf.predict_proba(X1_test)\n",
        "    log_loss_test = log_loss(y1_test, predict_y, eps=1e-15)\n",
        "    test_scores.append(log_loss_test)\n",
        "    print('estimators = ',i,'Train Log Loss ',log_loss_train,'Test Log Loss ',log_loss_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "odC7kt3dFt_Z",
        "colab": {}
      },
      "source": [
        "\n",
        "Depth = [5,10,12,15,20,25,50]\n",
        "test_scores = []\n",
        "train_scores = []\n",
        "for i in Depth:\n",
        "    clf = RFC(n_estimators=100,max_depth=i,n_jobs=-1)\n",
        "    clf.fit(X1_train,y1_train)\n",
        "    predict_y = clf.predict_proba(X1_train)\n",
        "    log_loss_train = log_loss(y1_train, predict_y, eps=1e-15)\n",
        "    train_scores.append(log_loss_train)\n",
        "    predict_y = clf.predict_proba(X1_test)\n",
        "    log_loss_test = log_loss(y1_test, predict_y, eps=1e-15)\n",
        "    test_scores.append(log_loss_test)\n",
        "    print('Depth = ',i,'Train Log Loss ',log_loss_train,'Test Log Loss ',log_loss_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ade_OW-uFt_b",
        "colab": {}
      },
      "source": [
        "#optimum depth = 11, optimum components = 400:\n",
        "clf = RFC(n_estimators=400,max_depth=11,n_jobs=-1)\n",
        "clf.fit(X1_train,y1_train)\n",
        "y_pred_rf = clf.predict(X1_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "N03CVKVfFt_d",
        "colab": {}
      },
      "source": [
        "confusion_matrix_rf = confusion_matrix(y1_test, y_pred_rf,labels = [1,0])\n",
        "print(confusion_matrix_rf)\n",
        "\n",
        "accuracy_rf = accuracy_score(y1_test,y_pred_rf)\n",
        "print(accuracy_rf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qjKROv6SFt_f",
        "colab": {}
      },
      "source": [
        "# RANDOM FOREST METRICS:- plot the confusion matrix, Average precision Recall, F1 score-\n",
        "from sklearn.metrics import f1_score,precision_score,recall_score\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from inspect import signature\n",
        "\n",
        "\n",
        "average_precision = average_precision_score(y1_test,y_pred_rf)    \n",
        "f1_score_rf = f1_score(y1_test,y_pred_rf)\n",
        "print(\"F1 Score of Random Forest classifier is:\",f1_score_rf)\n",
        "print(\"Confusion Matrix for Random Forest is:\",confusion_matrix_rf)\n",
        "print(\"precision score:\",precision_score(y1_test, y_pred_rf))\n",
        "print(\"Recall:\",recall_score(y1_test,y_pred_rf))\n",
        "print(\"Accuracy:\",accuracy_rf)\n",
        "print(\"Average Precision Recall Score:\",average_precision)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1K7AQ5sVKyX",
        "colab_type": "text"
      },
      "source": [
        "Fuzzy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3TkZse5WVU-F",
        "colab": {}
      },
      "source": [
        "X1 = df4.iloc[:,23:31]\n",
        "y1 = df4['is_duplicate']\n",
        "X1_train, X1_test, y1_train, y1_test =  train_test_split(X1, y1, test_size=0.2, random_state=42)\n",
        "X1_train, X1_val, y1_train, y1_val = train_test_split(X1_train, y1_train, test_size=0.13, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3lVz9TOrVU-J",
        "colab": {}
      },
      "source": [
        "#Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier as RFC\n",
        "estimators = [100,150,200,300,400,600,800]\n",
        "\n",
        "test_scores = []\n",
        "train_scores = []\n",
        "for i in estimators:\n",
        "    clf = RFC(n_estimators=i,n_jobs=-1)\n",
        "    clf.fit(X1_train,y1_train)\n",
        "    predict_y = clf.predict_proba(X1_train)\n",
        "    log_loss_train = log_loss(y1_train, predict_y, eps=1e-15)\n",
        "    train_scores.append(log_loss_train)\n",
        "    predict_y = clf.predict_proba(X1_test)\n",
        "    log_loss_test = log_loss(y1_test, predict_y, eps=1e-15)\n",
        "    test_scores.append(log_loss_test)\n",
        "    print('estimators = ',i,'Train Log Loss ',log_loss_train,'Test Log Loss ',log_loss_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R9hrmzv7VU-L",
        "colab": {}
      },
      "source": [
        "\n",
        "Depth = [5,10,12,15,20,25,50]\n",
        "test_scores = []\n",
        "train_scores = []\n",
        "for i in Depth:\n",
        "    clf = RFC(n_estimators=100,max_depth=i,n_jobs=-1)\n",
        "    clf.fit(X1_train,y1_train)\n",
        "    predict_y = clf.predict_proba(X1_train)\n",
        "    log_loss_train = log_loss(y1_train, predict_y, eps=1e-15)\n",
        "    train_scores.append(log_loss_train)\n",
        "    predict_y = clf.predict_proba(X1_test)\n",
        "    log_loss_test = log_loss(y1_test, predict_y, eps=1e-15)\n",
        "    test_scores.append(log_loss_test)\n",
        "    print('Depth = ',i,'Train Log Loss ',log_loss_train,'Test Log Loss ',log_loss_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kkmvm00YVU-O",
        "colab": {}
      },
      "source": [
        "#optimum depth = 11, optimum components = 400:\n",
        "clf = RFC(n_estimators=400,max_depth=11,n_jobs=-1)\n",
        "clf.fit(X1_train,y1_train)\n",
        "y_pred_rf = clf.predict(X1_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "05I9Iel0VU-Q",
        "colab": {}
      },
      "source": [
        "confusion_matrix_rf = confusion_matrix(y1_test, y_pred_rf,labels = [1,0])\n",
        "print(confusion_matrix_rf)\n",
        "\n",
        "accuracy_rf = accuracy_score(y1_test,y_pred_rf)\n",
        "print(accuracy_rf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fViFNbWgVU-S",
        "colab": {}
      },
      "source": [
        "# RANDOM FOREST METRICS:- plot the confusion matrix, Average precision Recall, F1 score-\n",
        "from sklearn.metrics import f1_score,precision_score,recall_score\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from inspect import signature\n",
        "\n",
        "\n",
        "average_precision = average_precision_score(y1_test,y_pred_rf)    \n",
        "f1_score_rf = f1_score(y1_test,y_pred_rf)\n",
        "print(\"F1 Score of Random Forest classifier is:\",f1_score_rf)\n",
        "print(\"Confusion Matrix for Random Forest is:\",confusion_matrix_rf)\n",
        "print(\"precision score:\",precision_score(y1_test, y_pred_rf))\n",
        "print(\"Recall:\",recall_score(y1_test,y_pred_rf))\n",
        "print(\"Accuracy:\",accuracy_rf)\n",
        "print(\"Average Precision Recall Score:\",average_precision)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnRhvqcUCPNm",
        "colab_type": "text"
      },
      "source": [
        "Fuzzy + Word2Vec Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3AGg7ArYCNkd",
        "colab": {}
      },
      "source": [
        "rng = list(range(1,15)) + list(range(23,30))\n",
        "X1 = df4.iloc[:,rng]\n",
        "y1 = df4['is_duplicate']\n",
        "X1_train, X1_test, y1_train, y1_test =  train_test_split(X1, y1, test_size=0.2, random_state=42)\n",
        "X1_train, X1_val, y1_train, y1_val = train_test_split(X1_train, y1_train, test_size=0.13, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-OoBcyCSCNkh",
        "colab": {}
      },
      "source": [
        "#Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier as RFC\n",
        "estimators = [100,150,200,300,400,600,800]\n",
        "\n",
        "test_scores = []\n",
        "train_scores = []\n",
        "for i in estimators:\n",
        "    clf = RFC(n_estimators=i,n_jobs=-1)\n",
        "    clf.fit(X1_train,y1_train)\n",
        "    predict_y = clf.predict_proba(X1_train)\n",
        "    log_loss_train = log_loss(y1_train, predict_y, eps=1e-15)\n",
        "    train_scores.append(log_loss_train)\n",
        "    predict_y = clf.predict_proba(X1_test)\n",
        "    log_loss_test = log_loss(y1_test, predict_y, eps=1e-15)\n",
        "    test_scores.append(log_loss_test)\n",
        "    print('estimators = ',i,'Train Log Loss ',log_loss_train,'Test Log Loss ',log_loss_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6T_dJWxsCNkj",
        "colab": {}
      },
      "source": [
        "\n",
        "Depth = [5,10,12,15,20,25,50]\n",
        "test_scores = []\n",
        "train_scores = []\n",
        "for i in Depth:\n",
        "    clf = RFC(n_estimators=100,max_depth=i,n_jobs=-1)\n",
        "    clf.fit(X1_train,y1_train)\n",
        "    predict_y = clf.predict_proba(X1_train)\n",
        "    log_loss_train = log_loss(y1_train, predict_y, eps=1e-15)\n",
        "    train_scores.append(log_loss_train)\n",
        "    predict_y = clf.predict_proba(X1_test)\n",
        "    log_loss_test = log_loss(y1_test, predict_y, eps=1e-15)\n",
        "    test_scores.append(log_loss_test)\n",
        "    print('Depth = ',i,'Train Log Loss ',log_loss_train,'Test Log Loss ',log_loss_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yGLqSDpYCNkm",
        "colab": {}
      },
      "source": [
        "#optimum depth = 11, optimum components = 400:\n",
        "clf = RFC(n_estimators=400,max_depth=11,n_jobs=-1)\n",
        "clf.fit(X1_train,y1_train)\n",
        "y_pred_rf = clf.predict(X1_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Qy1igBV-CNko",
        "colab": {}
      },
      "source": [
        "confusion_matrix_rf = confusion_matrix(y1_test, y_pred_rf,labels = [1,0])\n",
        "print(confusion_matrix_rf)\n",
        "\n",
        "accuracy_rf = accuracy_score(y1_test,y_pred_rf)\n",
        "print(accuracy_rf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-mKLM93lCNkq",
        "colab": {}
      },
      "source": [
        "# RANDOM FOREST METRICS:- plot the confusion matrix, Average precision Recall, F1 score-\n",
        "from sklearn.metrics import f1_score,precision_score,recall_score\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from inspect import signature\n",
        "\n",
        "\n",
        "average_precision = average_precision_score(y1_test,y_pred_rf)    \n",
        "f1_score_rf = f1_score(y1_test,y_pred_rf)\n",
        "print(\"F1 Score of Random Forest classifier is:\",f1_score_rf)\n",
        "print(\"Confusion Matrix for Random Forest is:\",confusion_matrix_rf)\n",
        "print(\"precision score:\",precision_score(y1_test, y_pred_rf))\n",
        "print(\"Recall:\",recall_score(y1_test,y_pred_rf))\n",
        "print(\"Accuracy:\",accuracy_rf)\n",
        "print(\"Average Precision Recall Score:\",average_precision)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}